{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7a47a-78f8-4eca-8c1c-16416933a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scist\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from rl import Rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3be5f-0982-43f3-9936-aea0cc0e3220",
   "metadata": {},
   "source": [
    "# Playground\n",
    "\n",
    "Below is to test how to do validation and training for policy evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fbf29-98a5-4d09-ae5c-52f283c5c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rollout_object():\n",
    "    env = gym.make(\n",
    "        \"LunarLander-v2\", \n",
    "    )\n",
    "    \n",
    "    gamma = 0.99\n",
    "    rollout = Rollout(env, gamma=gamma)\n",
    "    return env, rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e1c5b-bc50-4779-99fb-0907d352d6be",
   "metadata": {},
   "source": [
    "### Warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e26405-3645-479a-91f3-9ee6d66261f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(n_steps=4096):\n",
    "    (env, rollout) = get_rollout_object()\n",
    "    \n",
    "    s, info = env.reset()\n",
    "    for t in range(n_steps):\n",
    "        a = env.action_space.sample()\n",
    "        (s_next, r, term, trunc, info) = env.step(a)\n",
    "        rollout.add_step_data(s,a,r,term or trunc)\n",
    "        s = s_next\n",
    "    \n",
    "        if term or trunc:\n",
    "            s,_ = env.reset()\n",
    "    \n",
    "    # this is training data\n",
    "    return rollout.get_est_stateaction_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e27b9b-9478-451c-b00d-d0ae6965b874",
   "metadata": {},
   "source": [
    "### SGD for RKHS with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f6f62-fe3a-431f-a9a0-d895edc1c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing \n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fb0a8-708f-4d5c-a485-bc221b94fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "featurizer = PolynomialFeatures(1)\n",
    "featurizer = RBFSampler(gamma=1.0, n_components=100)\n",
    "\n",
    "# warm up\n",
    "n_warmup_steps = 100\n",
    "(env, rollout) = get_rollout_object()\n",
    "X = np.atleast_2d(np.array([env.observation_space.sample() for _ in range(n_warmup_steps)])).T\n",
    "featurizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb1db6-00ec-4c81-833f-72b86831814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_SGD(solver, X, y, n_epochs, max_regress = 5):\n",
    "    frac_val = 0.1\n",
    "    minibatch = 64\n",
    "    tol = 1e-3\n",
    "    \n",
    "    n_consec_regress_epochs = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i, shuffle=True, test_size=frac_val)\n",
    "        num_batches = int(np.ceil(len(X_train)/ minibatch))\n",
    "        for j in range(num_batches):\n",
    "            k_s = minibatch*j\n",
    "            k_e = min(len(X_train), minibatch*(j+1))\n",
    "            # mini-batch update\n",
    "            solver.partial_fit(X_train[k_s:k_e], y_train[k_s:k_e])\n",
    "\n",
    "        y_train_pred = solver.predict(X_train)\n",
    "        y_test_pred = solver.predict(X_test)\n",
    "\n",
    "        train_losses.append(la.norm(y_train_pred - y_train)**2/len(y_train))\n",
    "        test_losses.append(la.norm(y_test_pred - y_test)**2/len(y_test))\n",
    "\n",
    "        if len(test_losses) > 1 and test_losses[-1] > (1.+tol)*test_losses[-2]:\n",
    "            n_consec_regress_epochs += 1\n",
    "        else:\n",
    "            n_consec_regress_epochs = 0\n",
    "        if n_consec_regress_epochs == max_regress:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return np.array(train_losses), np.array(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ab4a3-0531-41df-9592-e6f19c22fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = RBFSampler(gamma=1.0, n_components=100)\n",
    "\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "    (\"rbf1\", RBFSampler(gamma=25, n_components=100)),\n",
    "    (\"rbf2\", RBFSampler(gamma=10, n_components=100)),\n",
    "    (\"rbf3\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "    (\"rbf4\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "    (\"rbf5\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "    (\"rbf6\", RBFSampler(gamma=0.5, n_components=100)),\n",
    "    (\"rbf7\", RBFSampler(gamma=0.1, n_components=100)),\n",
    "    (\"rbf8\", RBFSampler(gamma=0.01, n_components=100)),\n",
    "])\n",
    "\n",
    "(q_est, adv_est, s_visited, a_visited) = get_samples()\n",
    "act_mode = scist.mode(a_visited)[0].flat[0]\n",
    "idx_with_mode = np.where(np.squeeze(a_visited) == act_mode)\n",
    "X = featurizer.fit_transform(s_visited[idx_with_mode])\n",
    "y = q_est[idx_with_mode]\n",
    "\n",
    "# setup solve\n",
    "n_epochs = 200\n",
    "solver = SGDRegressor(max_iter=n_epochs, tol=1e-3, learning_rate=\"constant\", eta0=0.01)\n",
    "\n",
    "# train\n",
    "train_losses, test_losses = custom_SGD(solver, X, y, n_epochs)\n",
    "\n",
    "# plot\n",
    "plt.style.use('ggplot')\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.plot(np.arange(len(train_losses)), train_losses, label=\"train\", color=\"gray\")\n",
    "ax.plot(np.arange(len(test_losses)), test_losses, label=\"test\", linestyle=\"dotted\", color=\"red\")\n",
    "ax.set(xlabel=\"epoch\", ylabel=\"loss\", title=\"Cross validation\")\n",
    "ax.legend()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85635b-899e-4be3-b512-e2688973933e",
   "metadata": {},
   "source": [
    "Compare with `SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550e5a6-a638-4baa-88c2-05fb0e9bd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = solver.fit(X, y)\n",
    "print(f\"Final loss: {la.norm(solver.predict(X)-y)**2/len(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef5d72-5024-4d1c-8650-0c6da3d78d5e",
   "metadata": {},
   "source": [
    "### Compare runtime\n",
    "Let's compare runtime over `10` trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d487fbe-eed2-43c7-bb5a-048cc6de50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 32\n",
    "s_time = time.time()\n",
    "custom_sgd_losses = []\n",
    "for i in range(10):\n",
    "    (q_est, adv_est, s_visited, a_visited) = get_samples()\n",
    "    train_losses, test_losses = custom_SGD(solver, X, y, max_regress=np.inf, n_epochs=n_epochs)\n",
    "    custom_sgd_losses.append(train_losses[-1])\n",
    "total_time = time.time() - s_time\n",
    "print(f\"Total time: {total_time:.2f}s. Losses:\\n{custom_sgd_losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a9ba8-1012-4f35-b609-cbdfe429031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SGDRegressor(\n",
    "    max_iter=n_epochs, \n",
    "    tol=1e-3, \n",
    "    early_stopping=False, \n",
    "    learning_rate=\"constant\", \n",
    "    eta0=0.01\n",
    ")\n",
    "\n",
    "s_time = time.time()\n",
    "sgd_losses = []\n",
    "for i in range(10):\n",
    "    (q_est, adv_est, s_visited, a_visited) = get_samples()\n",
    "    solver.fit(X, y)\n",
    "    sgd_losses.append(la.norm(solver.predict(X)-y)**2/len(y))\n",
    "total_time = time.time() - s_time\n",
    "print(f\"Total time: {total_time:.2f}s. Losses:\\n{sgd_losses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec710830-d2e0-4393-868f-76e666d2d7c6",
   "metadata": {},
   "source": [
    "We can see the `SGDRegressor` is about 3-4x faster than our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9babee5-27ec-4c5a-a6fe-68fbaae59b30",
   "metadata": {},
   "source": [
    "# SGD for NN \n",
    "\n",
    "Start with imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11c63e-f780-4bed-bf07-8aa78eb350b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
